{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark Window Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql.session import SparkSession\n",
    "\n",
    "sc = SparkContext('local[2]', appName='local')  # local n specifies n threads\n",
    "spark = SparkSession(sc)  # defined spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import desc, row_number, monotonically_increasing_id, udf, pandas_udf, sum, count, round, col, greatest\n",
    "import pyspark.sql.functions as func\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.types import IntegerType, StringType, DoubleType\n",
    "\n",
    "from scipy import signal\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try Example UDF used in Bounded Spark Window\n",
    "\n",
    "* Spark 3.* allows bounded window, Spark 2.4 or below doesn't allow\n",
    "  * But you might need to modify the .conf file: https://stackoverflow.com/questions/62109276/errorjava-lang-unsupportedoperationexception-for-pyspark-pandas-udf-documenta\n",
    "* Spark 3.* prefers to use python type hints as udf return type, instead of using pandas type as the return type\n",
    "  * https://databricks.com/blog/2020/05/20/new-pandas-udfs-and-python-type-hints-in-the-upcoming-release-of-apache-spark-3-0.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+\n",
      "|  v|v_mean|\n",
      "+---+------+\n",
      "|  0|  null|\n",
      "|  2|   0.0|\n",
      "|  4|   1.0|\n",
      "|  6|   2.0|\n",
      "|  8|   3.0|\n",
      "| 10|   5.0|\n",
      "| 12|   7.0|\n",
      "| 14|   9.0|\n",
      "+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import pandas_udf\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "df1 = spark.range(0, 16, 2).toDF('v')\n",
    "w1 = Window.partitionBy().orderBy('v').rowsBetween(-4, -1)\n",
    "\n",
    "@pandas_udf('double')\n",
    "def myavg(v:pd.Series) -> float:\n",
    "    return v.mean()\n",
    "\n",
    "df1.withColumn('v_mean', myavg(df1['v']).over(w1)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try Exponential Sum in Moving Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+---+---------+\n",
      "|rid|Name|qty|has_color|\n",
      "+---+----+---+---------+\n",
      "|  1|   A| 10|        0|\n",
      "|  2|   A| 10|        0|\n",
      "|  3|   A| 10|        0|\n",
      "|  4|   A| 10|        0|\n",
      "|  5|   A| 10|        0|\n",
      "|  6|   A| 10|        0|\n",
      "|  7|   A| 10|        0|\n",
      "|  8|   A| 20|        1|\n",
      "|  9|   A| 20|        1|\n",
      "| 10|   A| 20|        1|\n",
      "+---+----+---+---------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.createDataFrame([\n",
    "    ('A', 10, 0), ('A', 10, 0), ('A', 10, 0), ('A', 10, 0), ('A', 10, 0),\n",
    "    ('A', 10, 0), ('A', 10, 0), ('A', 20, 1), ('A', 20, 1), ('A', 20, 1),\n",
    "    ('A', 20, 1), ('A', 20, 0), ('A', 20, 0), ('A', 20, 0), ('A', 20, 0),\n",
    "    ('A', 20, 1), ('A', 20, 1), ('A', 20, 0),\n",
    "    ('B', 10, 0), ('B', 10, 0), ('B', 10, 0), ('B', 10, 0), ('B', 10, 0),\n",
    "    ('B', 10, 0), ('B', 10, 0), ('B', 20, 1), ('B', 20, 1), ('B', 20, 1),\n",
    "    ('B', 20, 1), ('B', 20, 0), ('B', 20, 0), ('B', 20, 0), ('B', 20, 0),\n",
    "    ('B', 20, 1), ('B', 20, 1), ('B', 20, 0)\n",
    "], ['name', 'qty', 'has_color'])\n",
    "\n",
    "df = df.select('*').withColumn('rid', row_number().over(Window.orderBy(monotonically_increasing_id())))\n",
    "\n",
    "df = df.select(['rid', 'Name','qty', 'has_color']).cache()\n",
    "\n",
    "df.show(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+---+---------+----+----+\n",
      "|rid|Name|qty|has_color|col0|col1|\n",
      "+---+----+---+---------+----+----+\n",
      "|  1|   A| 10|        0|   0|   0|\n",
      "|  2|   A| 10|        0|   1|   0|\n",
      "|  3|   A| 10|        0|   2|   0|\n",
      "|  4|   A| 10|        0|   3|   0|\n",
      "|  5|   A| 10|        0|   4|   0|\n",
      "|  6|   A| 10|        0|   5|   0|\n",
      "|  7|   A| 10|        0|   6|   0|\n",
      "|  8|   A| 20|        1|   7|   0|\n",
      "|  9|   A| 20|        1|   7|   1|\n",
      "| 10|   A| 20|        1|   7|   2|\n",
      "| 11|   A| 20|        1|   7|   3|\n",
      "| 12|   A| 20|        0|   7|   4|\n",
      "| 13|   A| 20|        0|   7|   4|\n",
      "| 14|   A| 20|        0|   7|   4|\n",
      "| 15|   A| 20|        0|   7|   4|\n",
      "| 16|   A| 20|        1|   7|   3|\n",
      "| 17|   A| 20|        1|   7|   3|\n",
      "| 18|   A| 20|        0|   7|   3|\n",
      "| 19|   B| 10|        0|   0|   0|\n",
      "| 20|   B| 10|        0|   1|   0|\n",
      "| 21|   B| 10|        0|   2|   0|\n",
      "| 22|   B| 10|        0|   3|   0|\n",
      "| 23|   B| 10|        0|   4|   0|\n",
      "| 24|   B| 10|        0|   5|   0|\n",
      "| 25|   B| 10|        0|   6|   0|\n",
      "| 26|   B| 20|        1|   7|   0|\n",
      "| 27|   B| 20|        1|   7|   1|\n",
      "| 28|   B| 20|        1|   7|   2|\n",
      "| 29|   B| 20|        1|   7|   3|\n",
      "| 30|   B| 20|        0|   7|   4|\n",
      "| 31|   B| 20|        0|   7|   4|\n",
      "| 32|   B| 20|        0|   7|   4|\n",
      "| 33|   B| 20|        0|   7|   4|\n",
      "| 34|   B| 20|        1|   7|   3|\n",
      "| 35|   B| 20|        1|   7|   3|\n",
      "| 36|   B| 20|        0|   7|   3|\n",
      "+---+----+---+---------+----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "window_size = 7\n",
    "group = 'name'\n",
    "\n",
    "win_spec = Window.partitionBy([group]).orderBy('rid').rowsBetween(-window_size, -1) \n",
    "df = df.withColumn('col0', count('has_color').over(win_spec))\n",
    "df = df.withColumn('col1', sum('has_color').over(win_spec)).fillna(0)\n",
    "\n",
    "df.show(n=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.083390054218504\n",
      "[0.14285714 0.19758394 0.27327588 0.37796447 0.52275796 0.72302003\n",
      " 1.        ]\n"
     ]
    }
   ],
   "source": [
    "tau = -(window_size-1) / np.log(1.0/window_size)\n",
    "weights = np.array(list(reversed(signal.windows.exponential(window_size, tau=tau, center=0, sym=False))))\n",
    "\n",
    "print(tau)\n",
    "print(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+---+---------+----+----+------------------+\n",
      "|rid|Name|qty|has_color|col0|col1|              col2|\n",
      "+---+----+---+---------+----+----+------------------+\n",
      "|  1|   A| 10|        0|   0|   0|               0.0|\n",
      "|  2|   A| 10|        0|   1|   0|               0.0|\n",
      "|  3|   A| 10|        0|   2|   0|               0.0|\n",
      "|  4|   A| 10|        0|   3|   0|               0.0|\n",
      "|  5|   A| 10|        0|   4|   0|               0.0|\n",
      "|  6|   A| 10|        0|   5|   0|               0.0|\n",
      "|  7|   A| 10|        0|   6|   0|               0.0|\n",
      "|  8|   A| 20|        1|   7|   0|               0.0|\n",
      "|  9|   A| 20|        1|   7|   1|               1.0|\n",
      "| 10|   A| 20|        1|   7|   2| 1.723020026399484|\n",
      "| 11|   A| 20|        1|   7|   3| 2.245777984974194|\n",
      "| 12|   A| 20|        0|   7|   4| 2.623742457983421|\n",
      "| 13|   A| 20|        0|   7|   4|1.8970183412366195|\n",
      "| 14|   A| 20|        0|   7|   4|1.3715822511612057|\n",
      "| 15|   A| 20|        0|   7|   4|0.9916814354436382|\n",
      "| 16|   A| 20|        1|   7|   3| 0.613716962434411|\n",
      "| 17|   A| 20|        1|   7|   3|1.3404410791812125|\n",
      "| 18|   A| 20|        0|   7|   3|1.8658771692566267|\n",
      "| 19|   B| 10|        0|   0|   0|               0.0|\n",
      "| 20|   B| 10|        0|   1|   0|               0.0|\n",
      "| 21|   B| 10|        0|   2|   0|               0.0|\n",
      "| 22|   B| 10|        0|   3|   0|               0.0|\n",
      "| 23|   B| 10|        0|   4|   0|               0.0|\n",
      "| 24|   B| 10|        0|   5|   0|               0.0|\n",
      "| 25|   B| 10|        0|   6|   0|               0.0|\n",
      "| 26|   B| 20|        1|   7|   0|               0.0|\n",
      "| 27|   B| 20|        1|   7|   1|               1.0|\n",
      "| 28|   B| 20|        1|   7|   2| 1.723020026399484|\n",
      "| 29|   B| 20|        1|   7|   3| 2.245777984974194|\n",
      "| 30|   B| 20|        0|   7|   4| 2.623742457983421|\n",
      "| 31|   B| 20|        0|   7|   4|1.8970183412366195|\n",
      "| 32|   B| 20|        0|   7|   4|1.3715822511612057|\n",
      "| 33|   B| 20|        0|   7|   4|0.9916814354436382|\n",
      "| 34|   B| 20|        1|   7|   3| 0.613716962434411|\n",
      "| 35|   B| 20|        1|   7|   3|1.3404410791812125|\n",
      "| 36|   B| 20|        0|   7|   3|1.8658771692566267|\n",
      "+---+----+---+---------+----+----+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "@pandas_udf('double')\n",
    "def get_weighted_window(v: pd.Series) -> float:\n",
    "    v_len = len(v)\n",
    "    if v_len > 0:\n",
    "        return np.sum(np.dot(weights[-v_len:], v))\n",
    "    return 0\n",
    "\n",
    "win_spec = Window.partitionBy([group]).orderBy('rid').rowsBetween(-window_size, -1) \n",
    "df = df.withColumn('col2', get_weighted_window('has_color').over(win_spec))\n",
    "df.show(n=40)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
